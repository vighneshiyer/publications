{% extends "base/base.jinja2" %}

{# HTML title #}
{% set webpage_title = "Chisel/Chipyard Demo + The Next Paradigm of SoC Design" %}
{# Short description #}
{% set description = "" %}
{# List of authors #}
{% set author = "Joonho Whangbo, Vighnesh Iyer" %}
{# Change ‘venue’ to a conference or workshop name if any #}
{% set venue = "LATTE 2024" %}
{# Publication info (hidden by default) #}
{% set pub_datetime_iso = "2024-04-29" %}
{% set pub_date = "April 29, 2024" %}

{# Custom styles and JS for a particular talk #}
{% block custom_head %}
<style>
.reveal table.old_paradigm_table {
  width: 100%;
  font-size: 60%;
  border-collapse: separate;
  border-spacing: 0.1rem;
  margin-bottom: 1rem;
  tr > th {
    text-align:center;
    border: none;
  }
  tr > td {
      border: 2px solid black !important;
      border-radius: 5px;
  }
  tbody tr td {
      width: 16.6666%;
      height: 1rem;
      text-align: center;
      vertical-align: middle;
  }
  tbody tr th {
      vertical-align: middle;
  }
  tbody tr:nth-child(3) td:nth-child(3) {
  }
}
.reveal table.old_paradigm_table.new.visible {
  border-spacing: 0rem;
  tr > td {
    border-radius: 0;
    border: 0 !important;
  }
  tbody tr:nth-child(1) td {
      background: white !important;
    }
}
</style>
{% endblock %}

{% block theme %}
import '/themes/tokyonight-light.scss'
import 'highlight.js/styles/tokyo-night-dark.css'
{% endblock %}

{% block slides %}
<script type="module">
import Reveal from 'reveal.js';
Reveal.on( 'fragmentshown', event => {
  // event.fragment = the fragment DOM element
  var line_numbers = event.fragment.dataset.lineNumbers;
  var elem1 = document.getElementById("special1");
  var elem2 = document.getElementById("special2");
  if (line_numbers && line_numbers == "8,13,14,15,18,19") {
    elem1.style.opacity = 1;
    elem1.style.visibility = 'inherit';
  }
  if (line_numbers && line_numbers == "42") {
    elem1.style.opacity = 0;
    elem1.style.visibility = 'hidden';
    elem2.style.opacity = 1;
    elem2.style.visibility = 'inherit';
  }
} );
Reveal.on( 'fragmenthidden', event => {
  // event.fragment = the fragment DOM element
  var line_numbers = event.fragment.dataset.lineNumbers;
  var elem1 = document.getElementById("special1");
  var elem2 = document.getElementById("special2");
  if (line_numbers && line_numbers == "8,13,14,15,18,19") {
    elem1.style.opacity = 0;
    elem1.style.visibility = 'hidden';
  }
  if (line_numbers && line_numbers == "42") {
    elem1.style.opacity = 1;
    elem1.style.visibility = 'inherit';
    elem2.style.opacity = 0;
    elem2.style.visibility = 'hidden';
  }
} );
</script>

<section>
  <section class="center">
    <a href="https://github.com/ucb-bar">
      <img src="./figs/logos/BAR_vertical_logo.svg" class="image" style="height: 100px;">
    </a>
    <a href="https://github.com/ucb-bar/chipyard">
      <img src="./figs/logos/chipyard_logo.svg" class="image" style="height: 100px;">
    </a>
    <h2 class="fragment">The Next Paradigm of Hardware and SoC Design</h2>
    <h3>Chisel / Chipyard Overview + Demo</h3>
    <h4 style="font-weight:normal;">
      Joonho Whangbo, Vighnesh Iyer, Bora Nikolic (UC Berkeley)
    </h4>
    <h5 style="font-weight:normal;">
      LATTE 2024
    </h5>
  </section>
  <section>
    <h2>Talk Overview</h2>
    <ol>
      <li class="fragment">The existing paradigm of hardware design</li>
      <li class="fragment">What could come next? A view of the next paradigm of hardware design</li>
      <li class="fragment">Recent efforts to build the next paradigm
        <ul>
          <li class="fragment">New HDLs and design abstractions: <span class="small">Lava, Chisel, Amaranth, Spade, HeteroCL</span></li>
          <li class="fragment">New SoC design frameworks: <span class="small">Chipyard, ESP, OpenPiton, PULP, BlackParrot</span></li>
          <li class="fragment">New simulators: <span class="small">Verilator, FireSim, Manticore, Arcilator, RepCut, ESSENT</span></li>
        </ul>
      </li>
      <li class="fragment">What's still missing? Why are we not in the new age of hardware design?
        <ul>
          <li>It's a lot more than just the frontend language: PPA iteration cycle, verification, other stuff</li>
        </ul>
      </li>
      <li class="fragment">A sketch of what matters to hardware designers and our broad vision

      </li>
    </ol>
  </section>
</section>

<section>
  <section class="center">
    <h1>The Existing Paradigm of Hardware Design</h1>
    <h2>Seen in Industry</h2>
  </section>

  <section>
    <h2>People and Organization</h2>

    <table class="old_paradigm_table">
      <thead>
      <tr>
        <th></th>
        <th></th>
        <th colspan="5">Teams within an SoC Design Organization</th>
      </tr>
      <tr style="text-align: center;">
        <th></th>
        <th></th>
        <th>Spec / Arch</th>
        <th>Perf Modeling</th>
        <th>RTL</th>
        <th>DV</th>
        <th>PD</th>
      </tr>
      </thead>
      <tbody>
      <tr>
        <th rowspan="3" style="vertical-align: middle;">Design block</th>
        <th>Core</th>
        <td class="bg-red"></td>
        <td class="bg-orange"></td>
        <td></td>
        <td></td>
        <td></td>
      </tr>
      <tr>
        <th>LLC</th>
        <td class="bg-red"></td>
        <td class="bg-orange"></td>
        <td></td>
        <td></td>
        <td></td>
      </tr>
      <tr>
        <th>NPU</th>
        <td class="bg-red"></td>
        <td class="bg-orange"></td>
        <td></td>
        <td></td>
        <td></td>
      </tr>
      </tbody>
    </table>

    <ul>
      <li class="fragment">Highly specialized and large workforce</li>
      <li class="fragment">Teams are separated by function rather than design block</li>
      <li class="fragment">Duplicated work between specification, modeling, and RTL</li>
      <li class="fragment">Little interaction between teams</li>
      <li class="fragment">Complex tools and abstractions make transition between functions difficult</li>
    </ul>
  </section>

  <section>
    <h2>Specification</h2>
    <div class="center">
      <p><em>Insert picture of random excel spreadsheets, AXI spec documents, DDR state machines</em></p>
    </div>

    <ul>
      <li>English and Excel specs are the norm</li>
      <li>Simulators, models, and verification collateral are handcrafted rather than generated</li>
      <li>Translation errors due to undefined behaviors and misinterpretation are common</li>
    </ul>
  </section>

  <section>
    <h2>Languages + Semantics</h2>
    <div class="center">
      <p><em>Insert picture of ugly SystemVerilog macros, Perl generators</em></p>
    </div>

    <!--
    - ill defined / complex semantics, mixing simulation and synthesizable abstractions
    - multiple abstractions can only be blackboxed at the lowest level (practically)
    - massive monolithic simulation/emulation tools
    - macros on top of macros on top of web of Perl scripts
    -->
    <ul>
      <li>Most design is done at the RTL abstraction in Verilog/VHDL</li>
      <li>Limitations of these languages lead to a tower of macros on top of macros on top of a web of Perl</li>
      <li>Simulation / synthesis semantics mismatch</li>
      <li>Compositional semantics of mixing multiple abstractions isn't defined. Everything is lowered to RTL</li>
      <li>Simulation / emulation tools are massive monolithic blobs</li>
    </ul>
  </section>

  <section>
    <h2>SoC Integration / Construction</h2>
    <div class="center">
      <p><em>Image of Makefile calling other Makefiles and being wrapped in yet another custom build system</em></p>
    </div>

    <!--
    - web of scripts and build systems, config systems on top of config systems
    -->
    <ul>
      <li>Composing IP correctly is hard. Satisfying global constraints, verifying the interface</li>
      <li>SoC construction described in ad-hoc phases</li>
      <li>Collateral emission must synchronize the state and configuration of every IP</li>
    </ul>
  </section>

  <section>
    <h2>Iteration Speed</h2>

    <!--
      - it's not worth mentioning that industry uses handcrafted tools - i think that's not too related to iteration speed issues
    -->
    <ul>
      <li>Each new layer of tools adds latency from making a change to evaluation</li>
      <li>Current generation of tools has ad-hoc support for incremental compilation of the design and simulator</li>
      <li>It's well known that low iteration speed hampers developer productivity</li>
    </ul>
  </section>

  <section>
    <h2>Beauty / Elegance</h2>

    <ul>
      <li>Compare / contrast SystemC HLS vs Halide or EXO as an example</li>
      <li>How else can we demonstrate the lack of beauty?</li>
    </ul>
  </section>
</section>

<section>
  <section class="center">
    <h1>The Next Paradigm Shift of Hardware Design</h1>
  </section>

  <section>
    <h2>Flat Organization</h2>

    <table class="old_paradigm_table fragment custom new">
      <thead>
      <tr>
        <th></th>
        <th></th>
        <th colspan="5">Teams within an SoC Design Organization</th>
      </tr>
      <tr style="text-align: center;">
        <th></th>
        <th></th>
        <th>Spec / Arch</th>
        <th>Perf Modeling</th>
        <th>RTL</th>
        <th>DV</th>
        <th>PD</th>
      </tr>
      </thead>
      <tbody>
      <tr>
        <th rowspan="3" style="vertical-align: middle;">Design block</th>
        <th>Core</th>
        <td class="bg-red"></td>
        <td class="bg-orange"></td>
        <td></td>
        <td></td>
        <td></td>
      </tr>
      <tr>
        <th>LLC</th>
        <td class="bg-red"></td>
        <td class="bg-orange"></td>
        <td></td>
        <td></td>
        <td></td>
      </tr>
      <tr>
        <th>NPU</th>
        <td class="bg-red"></td>
        <td class="bg-orange"></td>
        <td></td>
        <td></td>
        <td></td>
      </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Rapid Iteration on all Axes</h2>
  </section>

  <section>
    <h2>Clean Interop of Multiple Paradigms</h2>
  </section>

  <section>
    <h2>New HDLs</h2>
  </section>

  <section>
    <h2>New Simulators</h2>
  </section>

  <section>
    <h2>New SoC Design Frameworks</h2>
  </section>

  <section>
    <h2>Main Ideas</h2>
    <dl>
      <dt>Frontends</dt>
      <dd>Mixed-abstraction, interop semantics, ergonomic external module integration, embedding PD/power/verification collateral</dd>
      <dt>IRs</dt>
      <dd>Preservation of semantics, graph-oriented representation</dd>
      <dt>Tools / Simulators</dt>
      <dd>Low latency iteration cycle (incremental)</dd>
    </dl>
  </section>
</section>

<section>
  <section class="center">
    <h2>Introduction to Chipyard and FireSim</h2>
  </section>

  <section class="center">
    <h2>What is Chipyard</h2>
    <ul>
      <li class="fragment">An organized framework for various SoC design tools</li>
      <li class="fragment">A curated IP library of open-source RISC-V SoC components</li>
      <li class="fragment">A methodology for agile SoC architecture design, exploration, and evaluation</li>
      <li class="fragment">A tapeout-ready chassis for custom RISC-V SoCs</li>
    </ul>
  </section>

  <section class="center">
    <h2>SoC Architecture</h2>
    <div class="container" style="grid-template-columns: 1.4fr 1.0fr;">
      <div>
        <img src="./figs/latte24/soc-arch.svg"/>
      </div>
      <div>
        <font size="6">
        <ul>
          <li class="fragment">We can configure the tiles, accelerators, memory hierarchy, and the interconnect.</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Tiles</h2>
    <div class="container" style="grid-template-columns: 1.4fr 1.0fr;">
      <div>
        <img src="./figs/latte24/soc-tiles.svg"/>
      </div>
      <div>
        <font size="5">
        <ul>
          <li class="fragment">Each Tile contains a RISC-V core and private caches</li>
          <li class="fragment">Several varieties of Cores supported</li>
          <ul>
            <li class="fragment">Rocket: 5-stage single-issue in-order</li>
            <li class="fragment">Shuttle: 6-stage superscalar in-order</li>
            <li class="fragment">SonicBOOM: 12-stage superscalar out-of-order</li>
          </ul>
          <li class="fragment">Interface supports integrating your own RISC-V core implementation</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>RoCC Accelerators</h2>
    <div class="container" style="grid-template-rows: 0.3fr 0.7fr;">
      <div>
        <font size="6">
          <ul>
            <li class="fragment">Tightly-coupled accelerator interface</li>
            <li class="fragment">Attach custom accelerators to Rocket or BOOM</li>
            <li class="fragment">Includes example implementations</li>
          </ul>
        </font>
      </div>
      <div>
        <img width="80%" src="./figs/latte24/soc-rocc-accel.svg"/>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>MMIO Accelerators</h2>
    <div class="container" style="grid-template-columns: 1.0fr 1.0fr;">
      <div>
        <img src="./figs/latte24/soc-mmio-accel.svg"/>
      </div>
      <div>
        <font size="6">
          <ul>
            <li class="fragment">Controlled by MMIO-mapped registers</li>
            <li class="fragment">Supports DMA to memory system</li>
          </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Bus Hierarchy</h2>
    <div class="container" style="grid-template-columns: 1.0fr 1.0fr;">
      <div>
        <img src="./figs/latte24/soc-bus-hierarchy.svg"/>
      </div>
      <div>
        <font size="5">
          <ul>
            <li class="fragment">Tilelink Standard:</li>
            <ul>
              <li class="fragment">TileLink is open-source chip-scale interconnect standard</li>
              <li class="fragment">Comparable to AXI/ACE</li>
              <li class="fragment">Supports multi-core, accelerators, peripherals, DMA, etc</li>
            </ul>
            <li class="fragment">Interconnect IP:</li>
            <ul>
              <li class="fragment">Library of TileLink RTL generators provided in RocketChip</li>
              <li class="fragment">RTL generators for crossbar-based buses</li>
              <li class="fragment">Width-adapters, clock-crossings, etc.</li>
              <li class="fragment">Adapters to AXI4, APB</li>
              <li class="fragment">New: Drop-in prefetchers</li>
            </ul>
          </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>NoC Interconnect</h2>
    <div class="container" style="grid-template-columns: 1.0fr 1.0fr;">
      <div>
        <img src="./figs/latte24/soc-noc.svg"/>
      </div>
      <div>
        <font size="5">
          <ul>
            <li class="fragment">Constellation:</li>
            <ul>
              <li class="fragment">Drop-in replacement for TileLink crossbar buses</li>
            </ul>
          </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>FireSim at 35,000 feet</h2>
    <font size="6">
    <ul>
      <li class="fragment">Open-source, fast, automatic, deterministic FPGA-accelerated <strong>hardware simulation</strong> for pre-silicon verification and performance validation.</li>
    </ul>
    </font>
  </section>

  <section class="center">
    <h2>Simulation vs Prototype</h2>
    <div class="container" style="grid-template-columns: 1.0fr 1.0fr;">
      <div>
        <img class="fragment" src="./figs/latte24/firesim-soc.png"/>
        <p class="fragment">SoC sees <strong>100</strong> cycles of DRAM latency.</p>
      </div>
      <div>
        <img class="fragment" src="./figs/latte24/firesim-prototype.png"/>
        <p class="fragment">SoC sees <strong>10</strong> cycles of DRAM latency. Wrong!</p>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Target vs Host</h2>
    <div class="container" style="grid-template-columns: 1.0fr 1.0fr;">
      <div>
        <img class="fragment" src="./figs/latte24/firesim-target.svg"/>
        <p class="fragment">Target: the machine under simulation.</p>
      </div>
      <div>
        <img class="fragment" src="./figs/latte24/firesim-host.svg"/>
        <p class="fragment">Host: the machine running the simulation.</p>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Host decoupling</h2>
    <div class="container" style="grid-template-columns: 1.0fr 1.0fr;">
      <div>
        <img class="fragment" src="./figs/latte24/firesim-before-transform.png"/>
      </div>
      <div>
        <ul>
          <li class="fragment">Starting with your target.</li>
        </ul>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Host decoupling</h2>
    <div class="container" style="grid-template-columns: 1.0fr 1.0fr;">
      <div>
        <img class="fragment" src="./figs/latte24/firesim-after-transform.png"/>
      </div>
      <div>
        <ul>
          <li class="fragment">Wrap the target RTL in a latency insensitive wrapper.</li>
          <li class="fragment">Attach a DRAM timing model using host FPGA resources.</li>
          <li class="fragment">These steps are automated by the FIRRTL compiler.</li>
        </ul>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Host decoupling</h2>
    <div class="container" style="grid-template-columns: 1.0fr 1.0fr;">
      <div>
        <img class="fragment" src="./figs/latte24/firesim-mapped.png"/>
      </div>
      <div>
        <ul>
          <li class="fragment">Map the simulation onto the host FPGA.</li>
          <li class="fragment">SoC now sees 100 cycles of DRAM latency!</li>
        </ul>
      </div>
    </div>
  </section>

<!-- - What PL people want : they want to integration accelerators built w/ their DSLs and evaluate it in the SoC context. -->
<!-- - We can provide an example on how to do this. -->
<!-- - Then we can explain about all the short commings of this approach. -->
<!-- - Janky, ad-hoc glue code -->
<!-- - SoC level parameter negotiation is difficult -->
<!-- - collateral generation (including compiler generation) -->
<!-- - FYI : compiler generation is basically generating software stubs to program the accelerator -->
<!-- - Then, we can explain about the two possible approaches. -->
<!-- - short-term approach : Graal VM + have a way of interchanging SoC level parameters (Diplomacy+++) -->
<!-- - long-term superior approach : unified frontend (we should also mention that the frontend should be extensible such that it doesn't limit further improvements in DSLs) -->
  <section class="center">
    <h2>Demo : Integrating External IP!</h2>
    <ul>
      <li class="fragment">How to integrate your own IP (generated from your own HDL) to perform full system SoC level evaluation?</li>
      <li class="fragment">What are the challenges during the integration process?</li>
      <li class="fragment">Future work on how we can fix the above problems as a community!</li>
    </ul>
  </section>

  <section class="center">
    <h3>Step 1 : Generate RTL from your HDL (e.g. Calyx)</h3>
    <pre data-id="code-animation"><code class="verilog" data-trim data-line-numbers="1">
    component CalyxSumBlackBox(in: 4) -> (out: 4) {
      cells { ... }
      wires { ... }
      control { ... }
    }
    </code></pre>
    <ul>
      <li class="fragment">Given a input, add it three times to itself and output it.</li>
    </ul>
  </section>

  <section class="center">
    <h3>Step 1 : Generate RTL from your HDL (e.g. Calyx)</h3>
    <pre data-id="code-animation"><code class="verilog" data-trim data-line-numbers>
    module CalyxSumBlackBox(
      input logic clk,
      input logic reset,

      input logic [3:0] in,
      input logic go,

      output logic [3:0] out,
      output logic done
    );
      ...
    endmodule
    </code></pre>
  </section>

  <section data-auto-animate>
    <h3>Step 2 : Create a BlackBox Module in Chipyard</h3>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers="1|2-9|12|13-14">
    class CalyxSumIO(nBits: Int) extends Bundle {
      val clk   = Input(Clock())
      val reset = Input(Bool())

      val in    = Input(UInt(nBits.W))
      val go    = Input(Bool())

      val out   = Output(UInt(nBits.W))
      val done  = Output(Bool())
    }

    class CalyxSumBlackBox(nBits: Int) extends BlackBox with HasBlackBoxResource {
      val io = IO(new CalyxSumIO(nBits))
      addResource("/vsrc/aggregator.sv")
    }
    </code></pre>
  </section>

  <section data-auto-animate>
    <h3>Step 3 : Generate a MMIO wrapper in Chipyard</h3>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers="1|14|18|19-51|54-59">
    class CalyxSumMMIOWrapper(
      params: CalyxSumParams, beatBytes: Int
    )(
      implicit p: Parameters
    ) extends ClockSinkDomain(ClockSinkParameters())(p) {
      val device = new SimpleDevice("calyx-sum", Seq("ucbbar,calyx-sum")) 
      val node = TLRegisterNode(Seq(AddressSet(params.address, 4096-1)), device, "reg/control", beatBytes=beatBytes)

      val nBits = params.nBits
      val nSum  = params.nSum

      override lazy val module = new MMIOWrapperImpl

      class MMIOWrapperImpl extends Impl with HasCalyxSumTopIO {
        val io = IO(new CalyxSumTopIO)

        withClockAndReset(clock, reset) {
          val bb    = Module(new CalyxSumBlackBox(nBits))
          val in_q  = Module(new Queue(UInt(nBits.W), params.qDepth))
          val out_q = Module(new Queue(UInt(nBits.W), params.qDepth))

          val go = RegInit(false.B)
          val cnt = RegInit(0.U(8.W))

          switch (go) {
            is (false.B) {
              when (in_q.io.count > 0.U && out_q.io.enq.ready) {
                go := true.B
                cnt := 0.U
              }
            }

            is (true.B) {
              when (bb.io.done) {
                go := false.B
              }
            }
          }

          bb.io.clk   := clock
          bb.io.reset := reset.asBool
          bb.io.go    := go
          bb.io.in    := in_q.io.deq.bits
          in_q.io.deq.ready := bb.io.done

          out_q.io.enq.bits  := bb.io.out
          out_q.io.enq.valid := bb.io.done
          io.done := bb.io.done

          when (bb.io.done) {
            assert(out_q.io.enq.ready)
          }

          node.regmap(
            0x00 -> Seq(RegField.r(1,     in_q.io.enq.ready)),
            0x04 -> Seq(RegField.w(nBits, in_q.io.enq)),
            0x08 -> Seq(RegField.r(1,     out_q.io.deq.valid)),
            0x0C -> Seq(RegField.r(nBits, out_q.io.deq))
          )
        }
      }
    }
    </code></pre>
  </section>

  <section data-auto-animate>
    <h3>Step 4 : Add stubs to attach the MMIO wrapper to a bus</h3>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers="1,7|2|9|10|12,13,28|14|15-18">
    case class CalyxSumParams(
      address: BigInt = 0x5000,
      qDepth: Int = 4,
      nBits: Int = 4,
      nSum: Int = 3)

    case object CalyxSumKey extends Field[Option[CalyxSumParams]](None)

    trait CanHaveMMIOCalyxSum { this: BaseSubsystem =>
      private val pbus = locateTLBusWrapper(PBUS)

      val calyx_sum_done = p(CalyxSumKey) match {
        case Some(params) => {
          val cs = LazyModule(new CalyxSumMMIOWrapper(params, pbus.beatBytes)(p))
          cs.clockNode := pbus.fixedClockNode
          pbus.coupleTo("calyx_sum_mmio_wrapper") {
            cs.node := TLFragmenter(pbus.beatBytes, pbus.blockBytes) := _
          }

          // Add port to DigitalTop (just for fun)
          val calyx_sum_done = InModuleBody {
            val done = IO(Output(Bool())).suggestName("calyx_sum_done")
            done := cs.module.io.done
            done
          }
          Some(calyx_sum_done)
        }
        case None => None
      }
    }
    </code></pre>
  </section>

  <section data-auto-animate>
    <h3>Step 5 : Mix the previous stub into your SoC</h3>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers="2,4-5">
    // DOC include start: DigitalTop
    class DigitalTop(implicit p: Parameters) extends ChipyardSystem
      ...
      // Enables optionally adding a Calyx generated module as a MMIO device
      with chipyard.example.CanHaveMMIOCalyxSum
    {
      override lazy val module = new DigitalTopModule(this)
    }
    </code></pre>
  </section>

  <section class="center">
    <h3>What did we just do?</h3>
    <img class="fragment" height=500px; src="./figs/latte24/demo-create-port.svg" />
  </section>

  <section data-auto-animate>
    <h3>Step 6 : Configure your SoC to use the MMIO module</h3>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers="1-3|5-6">
    class WithCalyxSum extends Config((site, here, up) => {
      case CalyxSumKey => Some(CalyxSumParams())
    })

    class CalyxSumRocketConfig extends Config(
      new chipyard.example.WithCalyxSum ++
      new freechips.rocketchip.subsystem.WithNBigCores(1) ++
      new chipyard.config.AbstractConfig)
    </code></pre>
    <p>At this point, the SoC level configuration is finished</p>
  </section>

  <section class="center">
    <h3>Overall SoC</h3>
    <img class="fragment" height=500px; src="./figs/latte24/demo-overall-soc.svg" />
  </section>

  <section data-auto-animate>
    <h3>Step 7 : Write software to talk to the MMIO device</h3>
    <pre data-id="code-animation"><code class="cpp" data-trim data-line-numbers="4-8|11,17,24,30|12,20,25,32">
    ...


    #define CALYX_SUM_BASE 0x5000
    #define CALYX_SUM_ENQ_RDY  (CALYX_SUM_BASE + 0)
    #define CALYX_SUM_ENQ_BITS (CALYX_SUM_BASE + 4)
    #define CALYX_SUM_DEQ_VAL  (CALYX_SUM_BASE + 8)
    #define CALYX_SUM_DEQ_BITS (CALYX_SUM_BASE + 12)


    static inline int calyx_sum_enq_ready() {
      int rdy = reg_read32(CALYX_SUM_ENQ_RDY);
      printf("calyx_sum_enq_ready: %d\n", rdy);
      return (rdy != 0);
    }

    static inline void calyx_sum_send_input(int val) {
      while (!calyx_sum_enq_ready());
      printf("sending input: %d\n", val);
      reg_write32(CALYX_SUM_ENQ_BITS, val & 0xf);
      printf("sending input done\n");
    }

    static inline int calyx_sum_deq_valid() {
      int val = reg_read32(CALYX_SUM_DEQ_VAL); 
      printf("calyx_sum_deq_val: %d\n", val);
      return (val != 0);
    }

    static inline int calyx_sum_get_output() {
      while (!calyx_sum_deq_valid());
      return reg_read32(CALYX_SUM_DEQ_BITS);
    }
    </code></pre>
  </section>

  <section data-auto-animate>
    <h3>Step 7 : Write software to talk to the MMIO device</h3>
    <pre data-id="code-animation"><code class="cpp" data-trim data-line-numbers="10|12|15-18,20">
    ...

    #define TEST_SIZE 3

    int main() {

      int test_inputs[TEST_SIZE] = {1, 2, 3};

      for (int i = 0; i &lt; TEST_SIZE; i++) {
        calyx_sum_send_input(test_inputs[i]);

        int out = calyx_sum_get_output();
        int expect = test_inputs[i] * 3;

        if (out != expect) {
          printf("expect %d got %d\n", expect, out);
          return 1;
        }
      }
      printf("[*] Test success!\n");
      return 0;
    }
    </code></pre>
  </section>

  <section data-auto-animate>
    <h3>Step 8 : Run SoC level integration tests</h3>
    <pre data-id="code-animation"><code class="bash" data-trim data-line-numbers="5">
    cd chipyard/tests
    make
    cd -
    cd chipyard/sims/verilator
    make -j$(nproc) run-binary CONFIG=CalyxSumRocketConfig BINARY=../../tests/calyx-sum.riscv
    </code></pre>
  </section>

  <section class="center">
    <h3>Step 8 : Run SoC level integration tests</h3>
    <img height=500px; src="./figs/latte24/calyx-uartlog.png" />
  </section>

  <section class="center">
    <h3>Challenges during the integration process</h3>
    <ul>
      <li class="fragment">Difficult to shared parameters btw the HDL and SoC framework.</li>
      <ul>
        <li class="fragment">HDL to SoC : port width of the module.</li>
        <li class="fragment">SoC to HDL : bus width, bus beats, addresses.</li>
      </ul>
      <li class="fragment">Diffult to DRY out the port definitions between the HDL and SoC framework.</li>
      <li class="fragment">Need a unified way of debugging the integration logic and the internal module.</li>
      <ul>
        <li class="fragment">HDL frameworks have their own way of debugging things (hard to look at waveforms of generated RTL).</li>
        <li class="fragment">We want to look at waveforms for the SoC level things.</li>
      </ul>
      <li class="fragment">Expected simulation semantics might differ between frameworks.</li>
    </ul>
  </section>

  <section class="center">
    <h3>How can we fix the above issues<br>(as a community)?</h3>
    <ul>
      <li class="fragment">Short term</li>
      <ul>
        <li class="fragment">Graal VM to build and interface frameworks built in different languages.</li>
        <li class="fragment">A library in Chipyard that exposes APIs that enables external frameworks to negotiate parameters with the SoC.</li>
      </ul>
      <li class="fragment">Long term</li>
      <ul>
        <li class="fragment">Unified language frontend that is highly extensible.</li>
        <li class="fragment">No more hacky DPI interfaces, or clunky libraries required.</li>
      </ul>
    </ul>
  </section>

  <section class="center">
    <h2>Resources</h2>
    <div class="container" style="grid-template-columns: 1.0fr 1.0fr;">
      <div>
        <img src="./figs/latte24/chipyard-docs.svg"/>
        <img src="./figs/latte24/firesim-docs.jpg"/>
      </div>
      <div>
        <ul>
          <li><a href="https://chipyard.readthedocs.io/en/stable/">Chipyard docs.</a></li>
          <li><a href="https://docs.fires.im/en/stable/">FireSim docs.</a></li>
          <li><a href="https://askjerry.net/">Ask me (Jerry) anything website!</a></li>
          <li><a href="https://fires.im/asplos-2023-tutorial/">Link to previous tutorial recordings</a></li>
        </ul>
      </div>
    </div>
  </section>

</section>

<!-- -------------------------------------------------------------------- -->

<section>
  <section class="center">
    <h2>The RTL First Design Methodology</h2>
    <p>"Just go write RTL"</p>
  </section>

  <section class="center">
    <h3>We need to reduce the NRE cost</h3>
    <img src="./figs/latte24/nre-cost.jpg"/>
  </section>

  <section class="center">
    <h3>Typical hardware design cycle</h3>
    <div class="container" style="grid-template-columns: 1.0fr 1.4fr;">
      <div class="fragment">
        <img src="./figs/latte24/design-process.svg" />
      </div>
      <div>
        <font size="6">
        <ul>
          <li class="fragment">Iterate over a design point in various abstractions.</li>
          <li class="fragment">You can get feedback from lower level abstractions.</li>
          <li class="fragment">You are likely to run <strong>a lot of simulations</strong> in order to get functionality and performance correct.</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h3>Time and effort is wasted</h3>
    <div class="container" style="grid-template-columns: 1.0fr 1.4fr;">
      <div class="fragment">
        <img src="./figs/latte24/compiling.png" />
      </div>
      <div>
        <font size="6">
        <ul>
          <li class="fragment">People just sit there waiting for code to compile or simulations to run.</li>
          <li class="fragment">Large companies can afford to have separate teams for each step of the design process.</li>
          <li class="fragment">Unsuitable for academics or startups with small teams.</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h3>RTL first design methodology</h3>
    <div class="container" style="grid-template-columns: 1.0fr 1.4fr;">
      <div class="fragment">
        <img src="./figs/latte24/design-process-rtl-first.svg" />
      </div>
      <div>
        <font size="6">
        <ul>
          <li class="fragment">Modeling is required because <strong>RTL writing is hard</strong>.</li>
          <li class="fragment">Modeling has a lot of errors and can lead designers to wrong conclusions.</li>
          <li class="fragment">Redundant work is done by writing code twice for the same design.</li>
          <li class="fragment">Make RTL writing so easy that we can just do modeling with RTL!</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Chisel</h2>
    <ul>
      <li class="fragment">HDL embedded in Scala.</li>
      <li class="fragment">Metaprogramming on top of the RTL abstraction.</li>
      <ul>
        <li class="fragment">Scala enables high expressiveness compared to SV.</li>
        <li class="fragment">Makes it much easier to read and write RTL.</li>
      </ul>
    </ul>
  </section>

  <section data-auto-animate>
    <h3>Reduced Sum : System Verilog</h3>
    <pre data-id="code-animation"><code class="verilog" data-trim data-line-numbers>
    module MyModule
      #(parameter N, M)
      (
        input  [N-1:0] a [0:M-1],
        output [N-1:0] sum
      );
      ...

    endmodule
    </code></pre>
  </section>

  <section data-auto-animate>
    <h3>Reduced Sum : System Verilog</h3>
    <pre data-id="code-animation"><code class="verilog" data-trim data-line-numbers="8-18">
    module MyModule
      #(parameter N, M)
      (
        input  [N-1:0] a [0:M-1],
        output [N-1:0] sum
      );

      reg [N-1:0] tmp [0:M];

      tmp[0] = a[0];
      sum = tmp[M];

      genvar i;
      generate
        for (i = 1; i &lt; M; i = i + 1) begin
          tmp[i] = tmp[i-1] + a[i];
        end
      endgenerate
    endmodule
    </code></pre>
  </section>

  <section data-auto-animate>
    <h2>Reduced Sum : Chisel</h2>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers>
    class MyModule(N: Int, M: Int) extends Module {
      val io = IO(new Bundle {
        val a = Vec(M, Input(UInt(N.W)))
        val sum  = Output(UInt(N.W))
      })
      ...
    }
    </code></pre>
  </section>

  <section data-auto-animate>
    <h2>Reduced Sum : Chisel</h2>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers="6">
    class MyModule(N: Int, M: Int) extends Module {
      val io = IO(new Bundle {
        val a = Vec(M, Input(UInt(N.W)))
        val sum  = Output(UInt(N.W))
      })
      io.sum := io.a.reduce(_ + _)
    }
    </code></pre>
  </section>

  <section class="center">
    <h2>Chisel as a embedded DSL</h2>
    <ul>
      <li class="fragment">Enables us to use existing tools around the host language.</li>
      <ul>
        <li class="fragment">Package manager.</li>
        <li class="fragment">Build systems.</li>
        <li class="fragment">LSP.</li>
      </ul>
    </ul>
  </section>

  <section class="center">
    <h2>FIRRTL</h2>
    <ul>
      <li class="fragment">Intermediate representation for Chisel.</li>
      <li class="fragment">Designed to represent the generated circuit after Chisel's elaboration (after all meta programming has executed).</li>
      <li class="fragment">Enables you to programmatically analyse and modify the circuit.</li>
      <li class="fragment">SSA style in memory representation.</li>
    </ul>
  </section>

  <section data-auto-animate>
    <h2>Reduced Sum : FIRRTL</h2>
    <pre data-id="code-animation"><code class="" data-trim data-line-numbers>
    circuit MyModule :
      module MyModule :
        ...
    </code></pre>
  </section>

  <section data-auto-animate>
    <h2>Reduced Sum : FIRRTL</h2>
    <pre data-id="code-animation"><code class="" data-trim data-line-numbers="2-5">
    circuit MyModule :
      module MyModule :
        input clock : Clock
        input reset : UInt&lbrack;1&rbrack;
        output io : { flip a : UInt&lbrack;4&rbrack;[4], sum : UInt&lbrack;4&rbrack;}

        node _io_sum_T = add(io.a[0], io.a[1]) @[MyModule.scala 14:27]
        node _io_sum_T_1 = tail(_io_sum_T, 1) @[MyModule.scala 14:27]
        node _io_sum_T_2 = add(_io_sum_T_1, io.a[2]) @[MyModule.scala 14:27]
        node _io_sum_T_3 = tail(_io_sum_T_2, 1) @[MyModule.scala 14:27]
        node _io_sum_T_4 = add(_io_sum_T_3, io.a[3]) @[MyModule.scala 14:27]
        node _io_sum_T_5 = tail(_io_sum_T_4, 1) @[MyModule.scala 14:27]
        io.sum &lt;= _io_sum_T_5 @[MyModule.scala 14:10]
    </code></pre>
    <p>FIRRTL resembles your circuit.</p>
  </section>

  <section data-auto-animate>
    <h2>Reduced Sum : FIRRTL</h2>
    <pre data-id="code-animation"><code class="" data-trim data-line-numbers="7-13">
    circuit MyModule :
      module MyModule :
        input clock : Clock
        input reset : UInt&lbrack;1&rbrack;
        output io : { flip a : UInt&lbrack;4&rbrack;[4], sum : UInt&lbrack;4&rbrack;}

        node _io_sum_T = add(io.a[0], io.a[1]) @[MyModule.scala 14:27]
        node _io_sum_T_1 = tail(_io_sum_T, 1) @[MyModule.scala 14:27]
        node _io_sum_T_2 = add(_io_sum_T_1, io.a[2]) @[MyModule.scala 14:27]
        node _io_sum_T_3 = tail(_io_sum_T_2, 1) @[MyModule.scala 14:27]
        node _io_sum_T_4 = add(_io_sum_T_3, io.a[3]) @[MyModule.scala 14:27]
        node _io_sum_T_5 = tail(_io_sum_T_4, 1) @[MyModule.scala 14:27]
        io.sum &lt;= _io_sum_T_5 @[MyModule.scala 14:10]
    </code></pre>
    <p>Metaprogramming has executed</p>
  </section>

  <section data-auto-animate>
    <h3>Cool things that FIRRTL enables</h3>
    <ul>
      <li class="fragment">FAME transformations and FireSim.</li>
      <figure>
        <img class="fragment" src="./figs/latte24/li-bdn-transformed.svg" />
        <figcaption class="fragment">Bold lines : Target design<br>Dashed lines : Timing control logic</figcaption>
      </figure>
    </ul>
  </section>

  <section data-auto-animate>
    <h3>Cool things that FIRRTL enables</h3>
    <ul>
      <li class="fragment">Scan-chains.</li>
      <li class="fragment">Error checking, generic compiler optimizations.</li>
      <ul>
        <li class="fragment">Combinational loop detection.</li>
        <li class="fragment">DCE, CSE, Const Prop.</li>
      </ul>
    </ul>
  </section>

  <section class="center">
    <h3>Overview of the Current Infrastructure</h3>
    <div class="container" style="grid-template-columns: 1.0fr 1.0fr;">
      <div class="fragment">
        <img src="./figs/latte24/tool-stack.svg" />
      </div>
      <div>
        <font size="6">
        <ul>
          <li class="fragment">Chisel & FIRRTL : Expressive frontend and flexible IR.</li>
          <li class="fragment">Chipyard : Composable SoC generator framework w/ a handful of grad students.</li>
          <li class="fragment">FireSim : Fast RTL simulation.</li>
          <li class="fragment">Enabled countless research projects from both industry and academia for the last 5+ years.</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Retrospective</h2>
    <ul>
      <li class="fragment">Have we realized the RTL first methodology to its full potential?</li>
      <ul>
        <li class="fragment">Compile time.</li>
        <li class="fragment">Simulation time.</li>
        <li class="fragment">Modeling time.</li>
      </ul>
    </ul>
  </section>

  <section class="center">
    <h2>Retrospective : Compile Time</h2>
    <font size="6">
    <ul>
      <li class="fragment">Compile time of our designs is longer than SystemVerilog based frameworks.</li>
      <li class="fragment">Extra steps introduced during compilation :<br>Chisel &rarr; FIRRTL & FIRRTL &rarr; Verilog</li>
      <li class="fragment">No concept of deduplication :<br>If you have 10 of the same modules (cores) it will run the same compiler passes on all of them.</li>
      <li class="fragment">Inefficient compiler passes due to wrong in memory representation.</li>
      <li class="fragment">Rebuild everything whenever approach (tied to the SoC generator framework internals).</li>
    </ul>
    </font>
  </section>

  <section class="center">
    <h3>Retrospective : Simulation Time</h3>
    <ul>
      <li class="fragment">FireSim drastically reduced the simulation "runtime".</li>
      <li class="fragment">However, it takes hours to just compile FireSim bitstreams, making it unsuitable for meaningful DSE and debugging.</li>
      <li class="fragment">Recent work (ESSENT & RepCut) that accelerates software RTL simulation suffers from long compilation times.</li>
    </ul>
  </section>

  <section class="center">
    <h3>Retrospective : Modeling Time</h3>
    <ul>
      <li class="fragment">We are still stuck at the RTL level abstraction.</li>
      <li class="fragment">Need a way of raising the level of abstraction in the initial phase of your design.</li>
      <li class="fragment">Must integrate existing tools that already do this <strong>seamlessly</strong> into our framework.</li>
      <ul>
        <li class="fragment">Commercial tools : Vivado HLS, SystemC, ...</li>
        <li class="fragment">Academic tools : Calyx, Dahlia, PyMetal, HeteroCl, Filament</li>
      </ul>
    </ul>
  </section>

  <section class="center">
  </section>

  <section class="center">
    <h3>Feature Requests</h3>
    <div class="container" style="grid-template-columns: 1.0fr 1.4fr;">
      <div>
        <img src="./figs/latte24/feature-request.jpg" />
      </div>
      <div>
        <font size="6">
        <ul>
          <li class="fragment">Fast compilation time as well as quick feedback from the backend tools.</li>
          <li class="fragment">Fast simulation that doesn't require hours of compile time.</li>
          <li class="fragment">Support for higher level abstractions to enable designers to work on various levels of abstractions.</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h3>Rest of the talk</h3>
    <img src="./figs/latte24/what-we-want.svg" />
  </section>
</section>

<!-- -------------------------------------------------------------------- -->

<section>
  <section class="center">
    <h2>Language Frontend</h2>
  </section>

  <section class="center">
    <h3>1. Reducing the Compile time</h3>
  </section>

  <section class="center">
    <h2>Chipyard Compile Steps</h2>
    <ul>
      <li class="fragment">Scala FIRRTL Compiler (SFC) : Compiles the scala sources and generates CHIRRTL.</li>
      <li class="fragment">MLIR FIRRTL Compiler (MFC) : Emits Verilog from CHIRRTL.</li>
      <li class="fragment">Verilator : Verilog to C++ binary.</li>
    </ul>
  </section>

  <section class="center">
    <h2>Chipyard Compile Steps</h2>
    <div class="container" style="grid-template-rows: 0.1fr 0.7fr;">
      <div>
        <font size="5">
        <ul>
          <li class="fragment">Imagine you are working on BOOM...</li>
          <li class="fragment">Waiting 10 minutes every time you find a bug, just to start RTL simulation...</li>
        </ul>
        </font>
      </div>
      <div>
        <img src="./figs/latte24/compile-time.svg" />
      </div>
    </div>
  </section>

  <section data-auto-animate>
    <h2>Incremental First</h2>
    <ul>
      <li class="fragment">Hardware designers want more iterations to perform experiments.</li>
      <li class="fragment">Most of the times, we write the entire module, and make small fixes to the control logic.</li>
    </ul>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers="6">
    class MyModule(N: Int, M: Int) extends Module {
      val io = IO(new Bundle {
        val a = Vec(M, Input(UInt(N.W)))
        val sum  = Output(UInt((N + M - 1).W))
      })
      io.sum := io.a.reduce(_ + _)
    }
    </code></pre>
  </section>

  <section data-auto-animate>
    <h2>Incremental First</h2>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers="6">
    class MyModule(N: Int, M: Int) extends Module {
      val io = IO(new Bundle {
        val a = Vec(M, Input(UInt(N.W)))
        val sum  = Output(UInt((N + M - 1).W))
      })
      io.sum := io.a.reduce(_ +& _)
    }
    </code></pre>
    <p class="fragment">Are you ready to wait 10 more minutes for your code to compile?</p>
  </section>

  <section class="center">
    <h2>Incremental First</h2>
    <ul>
      <li class="fragment">This problem can be solved by adopting the incremental first approach to hardware design.</li>
      <li class="fragment"><strong>Partial compilation & Cacheing.</strong></li>
    </ul>
  </section>

  <section class="center">
    <h2>Incremental First</h2>
    <img src="./figs/latte24/incremental-1.svg" />
  </section>

  <section class="center">
    <h2>Incremental First</h2>
    <img src="./figs/latte24/incremental-2.svg" />
    <ul>
      <li class="fragment">classfiles are cached by the build system of the host language.</li>
      <li class="fragment">Scala : <a href="https://mill-build.com/mill/Intro_to_Mill.html">mill</a></li>
    </ul>
  </section>

  <section class="center">
    <h2>Incremental First</h2>
    <img src="./figs/latte24/incremental-3.svg" style="width:80%;height:auto;"/>
    <ul>
      <li class="fragment">Builder has to manage the cache for the generated output (*.sv).</li>
    </ul>
  </section>

  <section class="center">
    <h2>Incremental First</h2>
    <img src="./figs/latte24/incremental-4.svg" style="width:80%;height:auto;"/>
    <ul>
      <li class="fragment">A1.class is invalidated by the host language build system.</li>
    </ul>
  </section>

  <section class="center">
    <h2>Incremental First</h2>
    <img src="./figs/latte24/incremental-5.svg" style="width:80%;height:auto;"/>
    <ul>
      <li class="fragment">Builder.class investigates A1.class to see if there are any changes made.</li>
    </ul>
  </section>

  <section class="center">
    <h2>Incremental First</h2>
    <ul>
      <li class="fragment">We get halfway there by just utilizing the host buildsystem.</li>
      <li class="fragment">The eDSL interpreter has to perform some tracking mechanism.</li>
    </ul>
  </section>

  <section class="center">
    <h3>2. Reducing the Modeling time</h3>
  </section>

  <section class="center">
    <h2>Mixed Abstractions</h2>
    <ul>
      <li class="fragment">We want to raise the level of abstraction to make HW design easier.</li>
      <ul>
        <li class="fragment">Accelerators, initial prototyping stage, (possibly) the bus hierarchy.</li>
      </ul>
      <li class="fragment">However, we also need lower level abstractions (RTL) when designing an SoC.</li>
      <ul>
        <li class="fragment">High perf cores and caches.</li>
      </ul>
    </ul>
  </section>

  <section class="center">
    <h3>Existing Abstractions</h3>
    <ul>
      <li class="fragment">Gate level : lets ignore this for now...</li>
      <li class="fragment">RTL : Explicitly defining registers and wires (e.g., Verilog, S-Verilog, Chisel).</li>
      <li class="fragment">Calyx : Explicit HW instantiations, imperative control flow.</li>
      <li class="fragment">HLS : High level descriptions, compiler does it all.</li>
    </ul>
  </section>

  <section class="center">
    <h2>Problems with Mixing</h2>
    <div class="container" style="grid-template-columns: 1.0fr 1.4fr;">
      <div>
        <img src="./figs/latte24/oil-water.jpg" />
      </div>
      <div>
        <font size="6">
        <ul>
          <li class="fragment">Clean (and good looking) APIs between the abstractions.</li>
          <li class="fragment">Compiler backend that can stitch different abstraction together.</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Clean API</h2>
    <ul>
      <li class="fragment">Mixing abstractions in the module granularity seems reasonable.</li>
      <ul>
        <li class="fragment">Clean separation of compilers between abstractions.</li>
        <li class="fragment">IO ports are concrete targets that the HLS compilers can try abstracting away.</li>
      </ul>
  </section>

  <section class="center">
    <h4>How should the HLS APIs look like in this world?</h4>
    <ul>
      <li class="fragment">Want to separate the compute description from the compiler flags (HeteroCL).</li>
      <li class="fragment">Want to specify the HLS compiler flags in a single location.</li>
      <ul>
        <li class="fragment">Easier to specify relationships between flags.</li>
        <li class="fragment">Cleaner code.</li>
      </ul>
      <li class="fragment">Want to abstract out the bus/RTL interface.</li>
      <li class="fragment">Want to pass parameters from the SoC side.</li>
    </ul>
  </section>

  <section data-auto-animate>
    <h2>API sketches for Embedded HLS</h2>
    <pre data-id="code-animation"><code class="python" data-trim data-line-numbers="1|11|12|14-16|18-19|23|24-27|29-32|34-37|39">
    class ExampleHLS:
      compiler_handles : List[Handles]
      bus_protocol  : str
      bus_bytes     : int
      input_len     : int
      unroll_factor : int

      def __init__(self):
        ...

      def compute(self, input : List[HLSInt]) -> HLSInt:
        sum = hls.init(0)

        # Although we are adding the loop_handle manually here, this can be hidden.
        (for_stmt, loop_handle) = hls.for()
        compiler_handles.append(loop_handle)

        for_stmt x in input:
          sum += x

        return sum

      def synthesize(self) -> IR:
        # Single place to specify HLS compiler options
        for h in compiler_handles:
          if h.is_loop_handle():
            h.unroll_loop(unroll_factor)

        # Bus and compute configurations
        hls.bus.set_protocol(bus_protocol)
        hls.bus.set_width(bus_bytes)
        f = hls.register_compute(self.compute)

        # Describe the dataflow
        input = hls.bus.read_and_save(input_len)
        output = f(input)
        hls.bus.write(output)

        return hls.compile()
    </code></pre>
  </section>

  <section class="center">
    <h2>Compiler Backend - Goals</h2>
    <div class="container" style="grid-template-columns: 1.4fr 1.0fr;">
      <div>
        <img src="./figs/latte24/backend-questionmark.svg" style="height: 500px;"/>
      </div>
      <div>
        <font size="6">
        <ul>
          <li class="fragment">High simulation performance (don't lower everying into RTL).</li>
          <li class="fragment">High QoR (need to preserve circuit semantics).</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Compiler Backend - RTL Simulation</h2>
    <div class="container" style="grid-template-columns: 1.4fr 1.0fr;">
      <div>
        <img src="./figs/latte24/backend-rtl-sim.png" style="height: 500px;"/>
      </div>
      <div>
        <font size="6">
        <ul>
          <li class="fragment">Instead of lowering higher level abstractions into RTL, emit discrete event models and link them during simulator compile time.</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Compiler Backend - RTL Simulation</h2>
    <div class="container" style="grid-template-columns: 1.4fr 1.0fr;">
      <div>
        <img src="./figs/latte24/backend-rtl-sim-details.png" style="height: 500px;"/>
      </div>
      <div>
        <font size="6">
        <ul>
        <li class="fragment">Need to define a common transaction scheme between various abstractions.</li>
        <li class="fragment">The scheduler can make optimizations across all abstractions.</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Compiler Backend - FPGA / ASIC</h2>
    <div class="container" style="grid-template-columns: 1.4fr 1.0fr;">
      <div>
        <img src="./figs/latte24/backend-fpga-asic.svg" style="height: 500px;"/>
      </div>
      <div>
        <font size="6">
        <ul>
          <li class="fragment">IRs such as Calyx & "RTL IR" should be able to preserve circuit semantics.</li>
          <li class="fragment">In the short term we can generate Verilog.</li>
          <li class="fragment">In the long term, fix backend tools to directly operate on the "RTL IR".</li>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section class="center">
    <h2>Compiler Backend - Overall</h2>
    <img src="./figs/latte24/backend-all.png" style="height: 500px;"/>
  </section>

  <section class="center">
    <h4>Miscellaneous : what should be the role of type-systems?</h4>
    <ul>
      <li class="fragment">We all love static types.</li>
      <li class="fragment">However, we shouldn't be obsessed by it.</li>
      <li class="fragment">Rule of thumb : should not hurt design productivity.</li>
      <li class="fragment">Things that it should do?</li>
      <ul>
        <li class="fragment">Check connection validity between signals.</li>
        <ul>
          <li class="fragment">E.g., you don't want to connect a clock signal into a reset port.</li>
        </ul>
        <li class="fragment">(For a eDSL), differentiate types between the DSL and host language.</li>
      </ul>
      <li class="fragment">Things that it shouldn't do?</li>
      <ul>
        <li class="fragment">Shouldn't make the language too verbose.</li>
        <li class="fragment">Shouldn't increase the compilation time significantly.</li>
        <li class="fragment">Shouldn't try to prove circuit properties that should be checked during runtime.</li>
      </ul>
    </ul>
  </section>
</section>

<!-- -------------------------------------------------------------------- -->

<section>
  <section class="center">
    <h2>Intermediate Representation (IR)</h2>
  </section>

  <section class="center">
    <h2>Incremental First</h2>
    <ul>
      <li class="fragment">As mentioned in the previous section, it is crucial to support <strong>incremental compilation and caching</strong>.</li>
      <li class="fragment">Arguably the most important feature to hardware designers.</li>
      <li class="fragment">If we take the embedded DSL approach, we don't have to redo this ourselves!</li>
      <li class="fragment">E.g., Rust already has 3rd party build cache tools (sccache).</li>
    </ul>
  </section>

  <section class="center">
    <h3>RTL Level IR : Better In Memory Representation</h3>
    <div class="container" style="grid-template-columns: 1.4fr 1.0fr;">
      <div>
        <img src="./figs/latte24/rtl-ir.png" style="height: 500px;" class="fragment"/>
      </div>
      <div>
        <font size="5">
        <ul>
          <li class="fragment">Why does this even matter?</li>
          <li class="fragment">The primitives available in your IR affects QoR.</li>
          <li class="fragment">The in memory representation of the circuit affects compiler performance.</li>
          <ul>
            <li class="fragment">Graph representation can affect graph traversal speed. <a href="https://www.hillelwayne.com/post/graph-types/">The hunt for missing datatypes</a></li>
          </ul>
        </ul>
        </font>
      </div>
    </div>
  </section>

  <section data-auto-animate>
    <h3>SSA Rep. Problem</h3>
    <p>FIRRTL's combinational loop detection pass</p>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers="1-6|23,27,31|8,13,14,15,18,19|42">
    class CheckCombLoops
        extends Transform
        with RegisteredTransform
        with DependencyAPIMigration {

      ...

      private def getStmtDeps(
        simplifiedModules: mutable.Map[String, AbstractConnMap],
        deps:              MutableConnMap
      )(s:                 Statement
      ): Unit = s match {
        case Connect(info, loc, expr) => ...
        case w: DefWire => ...
        case DefNode(info, name, value) =>
          ...
          getExprDeps(deps, lhs, info)(value)
        case m: DefMemory if (m.readLatency == 0) => ...
        case i: WDefInstance => ...
        case _ => s.foreach(getStmtDeps(simplifiedModules, deps))
      }

      private def run(state: CircuitState) = {
        ...
        topoSortedModules.foreach {
          ...
          case m: Module =>
            val portSet = m.ports.map(p => LogicNode(p.name)).toSet
            val internalDeps = new MutableDiGraph[LogicNode] with MutableEdgeData[LogicNode, Info]
            portSet.foreach(internalDeps.addVertex(_))
            m.foreach(getStmtDeps(simplifiedModuleGraphs, internalDeps))

            moduleGraphs(m.name) = internalDeps
            simplifiedModuleGraphs(m.name) = moduleGraphs(m.name).simplify(portSet)
            // Find combinational nodes with self-edges; this is *NOT* the same as length-1 SCCs!
            for (unitLoopNode &lt;- internalDeps.getVertices.filter(v =&gt; internalDeps.getEdges(v).contains(v))) {
              errors.append(new CombLoopException(m.info, m.name, Seq(unitLoopNode.name)))
            }

            for (scc &lt;- internalDeps.findSCCs.filter(_.length &gt; 1)) {
              val sccSubgraph = internalDeps.subgraph(scc.toSet)
              val cycle = findCycleInSCC(sccSubgraph)
              (cycle.zip(cycle.tail)).foreach({ case (a, b) =&gt; require(internalDeps.getEdges(a).contains(b)) })
              // Reverse to make sure LHS comes after RHS, print repeated vertex at start for legibility
              val intuitiveCycle = cycle.reverse
              val repeatedInitial = prettyPrintAbsoluteRef(Seq(m.name), intuitiveCycle.head)
              val expandedCycle = expandInstancePaths(m.name, moduleGraphs, moduleDeps, Seq(m.name), intuitiveCycle)
              errors.append(new CombLoopException(m.info, m.name, repeatedInitial +: expandedCycle))
            }
          case m => throwInternalError(s"Module ${m.name} has unrecognized type")
        }
        ...
      }
    }
    </code></pre>
    <div class="r-stack">
      <p id="special1" style="transition: all .2s ease; opacity: 0; visibility: hidden; will-change: opacity;">We are traversing the statements to build a graph of the nodes.</p>
      <p id="special2" style="transition: all .2s ease; opacity: 0; visibility: hidden; will-change: opacity;">We are traversing the graph once again to check for comb loops.</p>
    </div>
  </section>

  <section class="center">
    <h3>Graph Rep.</h3>
    <font size="6">
    <div class="container" style="grid-template-columns: 1.0fr 1.0fr;">
      <div>
        <ul>
          <li class="fragment">The above pattern of traversing the graph twice is a very common pattern in FIRRTL passes.</li>
          <li class="fragment">If we had a graph representation of the circuit, we wouldn't have had to traverse the circuit twice.</li>
        </ul>
      </div>
      <div>
        <ul>
          <li class="fragment">Compared to a SSA style, "human readable" IR, debugging passes might become more difficult.</li>
        </ul>
      </div>
    </div>
    </font>
  </section>

  <section class="center">
    <h3>Graph Rep. Implementation Details</h3>
    <div class="container" style="grid-template-columns: 1.0fr 1.4fr;">
      <div>
        <img src="./figs/latte24/lgraph.jpg">
      </div>
      <div>
        <font size="6">
        <ul>
          <li class="fragment">lGraph : high perf. graph based IR.</li>
          <ul>
            <li class="fragment">Hypergraph where each node represents a module and the edges represents the connections.</li>
            <ul>
              <li class="fragment">Submodules forms a graph within a node representing the parent module.</li>
            </ul>
            <li class="fragment">Mmaps disk pages onto virtual memory to reduce memcpy overheads.</li>
            <li class="fragment">Supports graph traversals such that you can access nodes located in adjacent cachelines.</li>
          </ul>
        </ul>
        </font>
      </div>
  </section>

  <section class="center">
    <h3>Graph Rep. Exploiting Parallelism</h3>
    <ul>
      <li class="fragment">Again, the compiler performance is crucial for HW designers : exploit parallelism.</li>
      <li class="fragment">The passes should be written as if it is working on a single thread.</li>
      <ul>
        <li class="fragment">The complexities of dealing with parallelism should be hidden from the pass-writer.</li>
      </ul>
      <li class="fragment">The interpreter (compiler) must be able to partition the graph and execute passes in parallel.</li>
    </ul>
  </section>

  <section class="center">
    <h4>FIRRTL In Memory Representation Problem 2</h4>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers>
    case class Mux(...)
    case class UIntLiteral(...)
    case class SIntLiteral(...)
    case class DefWire(...)
    case class DefRegister(...)
    case class DefInstance(...)
    case class DefMemory(...)
    abstract class PrimOp extends FirrtlNode
    </code></pre>
    <ul>
      <li class="fragment">Limited set of primitives &rarr; QoR may be low.</li>
      <li class="fragment">Compiler & backend tools spends a lot of time recreating semantics.</li>
    </ul>
  </section>

  <section class="center">
    <h4>Possible Primitives</h4>
    <pre data-id="code-animation"><code class="scala" data-trim data-line-numbers="9-12">
    case class Mux(...)
    case class UIntLiteral(...)
    case class SIntLiteral(...)
    case class DefWire(...)
    case class DefRegister(...)
    case class DefInstance(...)
    case class DefMemory(...)
    abstract class PrimOp extends FirrtlNode
    case class OH(...)
    case class PriorityMux(...)
    case class BoolLiteral(...)
    case class DecoupledInterface(...)
    </code></pre>
    <ul>
      <li class="fragment">Add more primitives such that we can preserve more higher level circuit semantics.</li>
      <li class="fragment">Need to find a good balance between pass writing vs QoR.</li>
    </ul>
  </section>

  <section class="center">
    <h3>Support for Multiple Abstractions</h3>
    <div class="container" style="grid-template-columns: 1.5fr 1.0fr;">
      <div class="fragment">
        <img src="./figs/latte24/backend-all.png" style="height: 500px;"/>
      </div>
      <div>
        <font size="5">
        <ul>
          <li class="fragment">As we discussed, the IRs have to be able to support multiple abstractions from the frontend.</li>
        </ul>
        </font>
      </div>
    </div>
  </section>
</section>

<!-- -------------------------------------------------------------------- -->

<section>
  <section class="center">
    <h2>Reference</h2>
  </section>
</section>

{% endblock %}
