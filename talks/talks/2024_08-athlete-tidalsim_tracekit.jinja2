{% extends "base/base.jinja2" %}

{# HTML title #}
{% set webpage_title = "TidalSim and TraceKit" %}
{# Short description #}
{% set description = "" %}
{# List of authors #}
{% set author = "Vighnesh Iyer" %}
{# Change ‘venue’ to a conference or workshop name if any #}
{% set venue = "ATHLETE Update" %}
{# Publication info (hidden by default) #}
{% set pub_datetime_iso = "2024-08-12" %}
{% set pub_date = "August 12, 2024" %}

{# Custom styles and JS for a particular talk #}
{% block custom_head %}
<style>
table.detailed_warmup_table {
  width: 100%;
  font-size: 60%;
  border-collapse: separate;
  tr > th {
    text-align:center;
    border: none;
  }
  tr > td {
      border: 1px solid white;
  }
  tr:last-child > td {
      border-bottom: 1px solid white !important;
  }
  tbody tr td {
      width: 16.6666%;
      height: 2rem;
      text-align: center;
      vertical-align: middle;
  }
  tbody tr th {
      vertical-align: middle;
  }
}
table.comparison_table {
  width: 100%;
  font-size: 60%;
  border-collapse: separate !important;
  thead > tr > th:first-child {
    border-right: 2px solid #222222;
  }
  tbody > tr > td:first-child {
    border-right: 2px solid #222222;
  }
}
</style>
{% endblock %}

{% block theme %}
import '/themes/tokyonight-light.scss'
import 'highlight.js/styles/tokyo-night-dark.css'
{% endblock %}

{% set center = true %}

{% set rightarrow = "<strong>→</strong>" %}

{% block slides %}
<section class="center">
  <h1>TidalSim and TraceKit</h1>
  <h2 style="font-weight: normal;">Explorations of Execution-Driven and Trace-Based Sampled Simulation</h2>
  <h5 style="font-weight: normal;"><strong>Vighnesh Iyer</strong>, Bora Nikolic</h5>

  <h4>ATHLETE Update<br />
  Monday, August 19th, 2024</h4>
</section>

<section>
  <section class="center">
    <h1>TidalSim Recap</h1>
    <ul>
      <li class="fragment">Sampled simulation <strong>using RTL simulation</strong>
        <ul>
          <li>Short sampling units with functional uArch warmup (a la SMARTs)</li>
          <li>Representative sampling (a la Simpoints)</li>
        </ul>
      </li>
      <li class="fragment">Custom uArch <strong>(RTL) state injection</strong>
        <ul>
          <li>L1 i/d cache functional warmup model to RTL state injection</li>
          <li>Can extend to any long-lived functional unit</li>
        </ul>
      </li>
      <li class="fragment">Enables <strong>high throughput and accurate</strong> simulation of long workloads
        <ul>
          <li>Avoid FPGA iteration latency when doing uArch exploration</li>
          <li>Enables direct iteration on the RTL (not a model)</li>
        </ul>
      </li>
    </ul>
  </section>

  <section>
    <h2>Why RTL-Level Sampled Simulation?</h2>
    <div class="container" style="grid-template-columns: 1.4fr 1fr;">
      <div class="fragment">
        <img class="image" src="./figs/dynamic/tidalsim/why_rtl.svg" />
      </div>
      <div>
        <ul class="smallish">
          <li class="fragment">In any sampled simulation flow we see time modeling, sampling, and warmup errors</li>
          <li class="fragment">Direct use of RTL <strong>avoids modeling errors</strong> from uArch models
            <ul>
              <li class="fragment">No need to correlate performance model and RTL</li>
              <li class="fragment">Let the RTL serve as the source of truth</li>
            </ul>
          </li>
          <li class="fragment">Produce RTL-level collateral
            <ul>
              <li>Leverage for applications in verification and power modeling</li>
            </ul>
        </ul>
      </div>
    </div>
  </section>

  <section>
    <h2>Sampled Simulation Overview</h2>

    <p class="center fragment">Don't run the full workload in detailed simulation</p>
    <p class="center fragment smallish">Run the workload in <em>ISA simulation</em> and pick <em>samples</em> to run in uArch simulation</p>

    <div class="fragment center">
      <img class="image no-margin" width="60%" src="./figs/multi-level-sim/sampled_simulation0.png" />
    </div>

    <p class="fragment center">The full workload is represented by a selection of <em>sampling units</em>.</p>

    <ol class="smallish">
      <li class="fragment"><strong>Sampling unit length</strong>: tradeoff runtime and resolution</li>
      <li class="fragment"><strong>Warmup models</strong>: which uArch units to initialize</li>
      <li class="fragment"><strong>Clustering and extrapolation</strong>: how sampling units should be selected and used for prediction</li>
      <!--How can we estimate errors when extrapolating from sampling units?</li>--> <!-- error bounding via CLT or other heuristics -->
    </ol>
  </section>

  <section data-visibility="hidden">
    <h2>Functional Warmup</h2>

    <p class="fragment center">The state from a sampling unit checkpoint is only <em>architectural</em> state. The <em>microarchitectural</em> state of the uArch simulator starts at the reset state!</p>

    <div class="fragment center">
      <img width="50%" class="image" src="./figs/multi-level-sim/sampled_simulation.png" />
    </div>

    <ul>
      <li class="fragment">We need to seed long-lived uArch state at the beginning of each sampling unit</li>
      <li class="fragment">This process is called <em>functional warmup</em></li>
    </ul>
  </section>

  <section style="text-align: center;">
    <h2>Overview of the TidalSim Flow</h2>
    <img class="image" src="./figs/dynamic/tidalsim/overview.svg" />
  </section>

  <section>
    <h2>Functional Warmup Flow</h2>
    <div class="center">
      <img class="image no-margin" src="./figs/dynamic/tidalsim/full_flow_detail.svg" />
    </div>

    <ol>
      <li class="fragment">Full run of the binary on spike + sampling unit embedding + clustering</li>
      <li class="fragment">Re-run spike to capture arch checkpoints at the start of sampling units</li>
      <li class="fragment">Reconstruct L1d cache state for each arch checkpoint</li>
      <li class="fragment">Inject sampling units into RTL sim and extrapolate</li>
    </ol>

    <!--<ul class="small">
      <li class="fragment">uarch-agnostic cache checkpoints as memory timestamp record (MTR) checkpoints</li>
      <li class="fragment">MTR checkpoints {{ rightarrow }} cache state with cache parameters and DRAM contents</li>
      <li class="fragment">RTL simulation harness injects cache state into L1d tag+data arrays via 2d reg forcing</li>
    </ul>-->
  </section>

  <section>
    <h2>IPC Trace Reconstruction - wikisort</h2>

    <p class="center smallish">wikisort benchmark from embench, $N = 10000$, $C = 18$, $n_{\text{detailed}} = 2000$</p>

    <div class="fragment center">
      <img class="image no-margin" src="./figs/multi-level-sim/05_2024/wikisort.svg" />
      <figcaption class="fragment">$MAPE_{IPC} = 12.3\% \rightarrow 4.5\%$</figcaption>
    </div>
  </section>

  <section>
    <h2>IPC Trace Reconstruction - huffbench</h2>

    <p class="center smallish">huffbench benchmark from embench, $N = 10000$, $C = 18$, $n_{\text{detailed}} = 2000$</p>

    <div class="fragment center">
      <img class="image no-margin" src="./figs/multi-level-sim/05_2024/huffbench.svg" />
      <figcaption class="fragment">L1d functional warmup prevents gross IPC underprediction in most cases. $MAPE_{IPC} = 6.6\% \rightarrow 4.1\%$</figcaption>
    </div>
  </section>
</section>

<section>
  <section class="center">
    <h1>Multithreaded Workload Sampling</h1>
  </section>

  <section>
    <h2>Multithreaded Workloads</h2>

    <ul>
      <li class="fragment">HPC (NAS, ScaLAPACK, MPI (Intel/SPEC), Eigen, Cinebench, zstd)
        <ul>
          <li class="fragment">Compute/memory BW heavy</li>
          <li class="fragment">Frequent inter-thread communication</li>
          <li class="fragment">Native use of OS threads</li>
          <li class="fragment">Insensitive to OS scheduling, stable thread contexts</li>
        </ul>
      </li>
      <li class="fragment"><strong>Datacenter</strong> (nginx, Postgres, Redis, Gitlab)
        <ul>
          <li class="fragment">IO heavy</li>
          <li class="fragment">Task-level parallelism, low ILP, inter-thread communication on task init/finish</li>
          <li class="fragment">OS threads used for blocking IO (network, disk, database, RPC)</li>
          <li class="fragment">High concurrency, userspace threading (green threads), frequent context switches</li>
        </ul>
      </li>
    </ul>

    <p class="fragment center">Accurate modeling of time is essential for datacenter workloads</p>
  </section>

  <section>
    <h2>Modeling Time in Sampled Simulation</h2>

    <div class="center fragment">
      <img width="80%" src="./figs/dynamic/tidalsim/timer_interrupts.svg" />
    </div>

    <!--<p class="center fragment">Consider timer interrupts: naive functional simulators will just advance one timestep per commited instruction, not matching RTL!</p>-->
    <p class="center fragment">Live sampling (interleaving arch and uArch sim) is required to accurately model time-dependent behaviors.</p>
  </section>

  <section>
    <h2>Prior Work in Multithreaded Sampling</h2>

    <!--<ul>
      <li class="fragment">Prior work runs uArch simulators in "syscall emulation" mode when evaluating workloads (e.g. SPEC), not modeling any OS-application interactions</li>
      <li class="fragment">Real workloads contain many interactions between processes and the OS which are sensitive to the modeling of time</li>
    </ul>-->

    <ul>
      <li class="fragment">Focus on specialized ways of selecting sampling units
        <ul class="fragment">
          <li>TaskPoint<sup>[1]</sup>: task regions in task-based programming models</li>
          <li>BarrierPoint<sup>[2]</sup>: barriers</li>
          <li>LoopPoint<sup>[3]</sup>: loops</li>
        </ul>
      </li>
      <li class="fragment">Workloads were mostly HPC oriented: clean </li>
      <li class="fragment">Accurate time modeling requires live sampling (see COTSON from HP Labs)</li>
    </ul>

    <div class="verysmall fragment">
      <p class="footnote">
      [1]: T. Grass, et. al. TaskPoint: Sampled simulation of task-based programs. 2016 ISPASS<br />
      [2]: T. E. Carlson, et. al., BarrierPoint: Sampled simulation of multi-threaded applications. 2014 ISPASS<br />
      [3]: A. Sabu, et. al., LoopPoint: Checkpoint-driven Sampled Simulation for Multi-threaded Applications. 2022 HPCA<br />
      [4]: E. Argollo, et. al. COTSon: infrastructure for full system simulation. SIGOPS 2009
      </p>
    </div>
  </section>

  <section>
    <h2>Trace-Oriented Sampling</h2>
    Before trying to do live sampling with time modeling, let's figure out what sampling methodology is required to extrapolate performance (not considering injection related errors).
    Trace-oriented sampling methodology
    How we attempt to evaluate sampling errors alone

    Put a picture here - a long trace with trace statistics every X time, embed every trace slice, do clustering and extrapolation and figure out the sampling error
    This gives us the most optimistic picture, but only can evaluate sampling errors
  </section>

  <section>
    <h2>Multithreaded Embeddings</h2>

    Diagram of multicore activity and app threads being multiplexed onto each core.
    Do we want to do a single-core oriented embedding and extrapolation, or do we need to account for thread interaction (cache pollution and sharing effects)? To what degree do we need a "SoC-level embedding"?
  </section>
</section>

<section>
  <section class="center">
    <h1>Tracing @ Google</h1>
  </section>

  <section>
    <h2>Tracing Technologies</h2>

    DynamoRIO
    Abstraction over low-level tracing APIs (Intel PIN, Intel PT, ARM equivalent)
    Dynamic instrumentation, extract PC/branch/memory traces (with substantial application perturbation)
  </section>

  <section>
    <h2>DynamoRIO Traces</h2>
    Attach picture of trace view with ifetch, branches, markers, and so forth
    App-thread oriented traces, have to be reconstructed into core-oriented traces
  </section>

  <section>
    <h2>Published Memtraces</h2>
    Show the memtraces we have access to. Not including the internal ones at Google.
    What info is missing? Inst encodings, exact syscall reasons, IO activity
  </section>
</section>

<section>
  <section class="center">
    <h1>The TraceKit Framework</h1>
  </section>

  <section>
    <h2>Unified Trace Analysis Framework</h2>
    Unifying trace analysis for trace-oriented and execution-driven simulation flows.
    Abstraction over ISAs too.
    Diagram of TraceKit ingesting DynamoRIO traces with a scheduler onto a core-oriented model + direct ingestion of spike/RTL sim/FireSim traces
    Analysis passes are also included
    Later flow for live sampled simulation with time feedback
  </section>

    - Analysis framework
    - Diagram of how it integrates
    - Diagram of the scheduler
    - Diagram of how to unify it with TidalSim execution driven flow
    - Plans for evaluating trace-driven vs execution-driven simulation sampling and validity
</section>

<section>
  <section class="center">
    <h1>Experiments in Progress</h1>
  </section>
</section>

<section>
  <h2>Conclusion</h2>

  <div class="container" style="grid-template-columns: 1fr 1.5fr;">
    <img class="image" width="100%" src="./figs/dynamic/tidalsim/overview.svg" />
    <!--<img class="image" width="100%" src="./figs/dynamic/tidalsim/full_flow_detail.svg" />-->
    <img class="image" width="100%" src="./figs/multi-level-sim/05_2024/wikisort.svg" />
  </div>

  <div class="center">
  </div>

  <ul class="smallish">
    <!--<li class="fragment">We want to enable rapid RTL iteration with performance evaluation and generation of RTL-level collateral</li>-->
    <li class="fragment">We need fast, low-startup-latency RTL-level simulation</li>
    <li class="fragment">We propose a simulation methodology based on sampled RTL simulation
      <ul>
        <li>Small intervals + functional warmup with RTL simulation</li>
      </ul>
    </li>
    <li class="fragment">Everything is open source
      <ul><li><a href="https://github.com/euphoric-hardware/tidalsim">TidalSim (github.com/euphoric-hardware/tidalsim)</a> <small>Forks of spike, chipyard, testchipip + top-level runner</small></li></ul>
    </li>
  </ul>
</section>

<section>
  <section class="center">
    <h1>Extra Slides</h1>
  </section>

  <section>
    <h2>Existing Sampling Techniques</h2>

    <div class="container" style="grid-template-columns: 1fr 1fr;">
    <div>
    <h3 class="center fragment">SimPoint</h3>
    <div class="fragment image no-padding" style="display:grid; align-content: center; justify-items:center; grid-template-columns:1fr 1fr;">
      <img class="no-margin" style="display:grid;" src="./figs/multi-level-sim/simpoint-gzip_phases.gif" />
      <img class="no-margin" style="display:grid;" src="./figs/multi-level-sim/simpoint-gcc_phases.gif" />
    </div>
    <ul class="small">
      <li class="fragment">Workloads can be split into <strong style="text-decoration:underline;">phases</strong> that exhibit similar μArch behavior</li>
      <li class="fragment">SimPoint-style representative sampling
        <ul class="fragment">
          <li>Compute an embedding for each program interval (e.g. blocks of 100M instructions)</li>
          <li>Cluster interval embeddings using k-means</li>
          <li>Choose representative intervals from each cluster as <em>sampling units</em></li>
        </ul>
      </li>
    </ul>
    </div>
    <div>
      <h3 class="center fragment">SMARTS</h3>
      <img class="fragment image no-margin no-padding" src="./figs/quals/smarts.png" />
      <ul class="small">
        <li class="fragment">If we sample from a population, we can estimate the population mean</li>
        <!--<li class="fragment">Rigorous statistical sampling enables computation of confidence bounds
          <ul class="fragment">
            <li>Use random sampling on a full execution trace to derive a population sample</li>
            <li>Central limit theorem provides confidence bounds</li>
          </ul>
        </li>-->
        <li class="fragment">SMARTS-style random sampling
          <ul class="fragment">
            <li>Pick a large number of samples to take before program execution</li>
            <li>If the sample variance is too high after simulation, then collect more sampling units</li>
            <li>Use CLT to derive a confidence bound for the aggregate performance metric</li>
          </ul>
        </li>
      </ul>
    </div>
    </div>

    <p class="center fragment"><strong>Our proposal</strong>: Combine SimPoint-style representative sampling with SMARTS-style small intervals</p>
  </section>

  <section>
    <h2>Implementation Details For TidalSim</h2>
    <div class="container" style="grid-template-columns: 1.2fr 1fr;">
    <div>
    <ul class="smallish">
      <li class="fragment">Basic block identification
        <ul><li>BB identification from spike commit log or from static ELF analysis</li></ul>
      </li>
      <li class="fragment">Basic block embedding of intervals</li>
      <li class="fragment">Clustering and checkpointing
        <ul>
          <li>k-means, PCA-based n-clusters</li>
          <li>spike-based checkpoints</li>
        </ul>
      </li>
      <li class="fragment">RTL simulation and performance metric extraction
        <ul><li>Custom force-based RTL state injection, out-of-band IPC measurement</li></ul>
      </li>
      <li class="fragment">Extrapolation
        <ul><li>Estimate IPC of each interval based on its embedding and distances to RTL-simulated intervals</li></ul>
      </li>
    </ul>
    </div>
    <div style="display:grid; align-content: center;">
      <img class="image no-margin" src="./figs/dynamic/tidalsim/overview.svg" />
    </div>
    </div>
  </section>

  <section>
    <h2>Memory Timestamp Record</h2>
    <div class="center">
      <img class="image" src="./figs/dynamic/tidalsim/mtr_flow.svg" />
    </div>

    <ul class="small">
      <li class="fragment">Construct MTR table from a memory trace, save MTR tables at checkpoint times</li>
      <li class="fragment">Given a cache with n sets, group block addresses by set index</li>
      <li class="fragment">Given a cache with k ways, pick the k most recently accessed addresses from each set</li>
      <li class="fragment">Knowing every resident cache line, fetch the data from the DRAM dump</li>
    </ul>
  </section>

</section>

{% endblock %}
