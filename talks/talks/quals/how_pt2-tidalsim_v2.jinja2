<section>
  <section class="center">
    <h2>6. How (pt 2): TidalSim v2</h2>

    <p class="center fragment">The proposal is structured as 3 novel extensions to TidalSim v1 that address its limitations in fundamental ways.</p>

    <ol style="list-style-type:lower-alpha;">
      <li class="fragment">Unvalidated functional warmup models
        <ul class="small">
          <li>{{ rightarrow }} leverage verification libraries and fuzzing to automatically discover mismatches between the warmup model and RTL</li>
        </ul>
      </li>
      <li class="fragment">Inaccurate modeling of time-driven events (e.g. timer interrupts)
        <ul class="small">
          <li>{{ rightarrow }} dynamically moving between arch and RTL simulation to estimate time</li>
        </ul>
      </li>
      <li class="fragment">Only works with processor cores and not heterogeneous IP
        <ul class="small">
          <li>{{ rightarrow }} extend sampled simulation to accelerators</li>
        </ul>
      </li>
      <!--<li class="fragment">(Optional) Hardcoded sampling methodology prevents exploration of the accuracy/throughput tradeoff space
        <ul class="small">
          <li>{{ rightarrow }} generalizing the spectrum of streaming sampled RTL simulation</li>
          <li>{{ rightarrow }} generalizing representative sampling for PC/binary-agnostic interval embeddings to enable running multi-process workloads in an OS</li>
        </ul>
      </li>-->
    </ol>

    <!-- The limitations that still exist:
    - can't work with an OS (due to virtual PCs from instruction trace conflicting with multiple processes and having incorrect basic block embeddings)
    - can't model timing accurately including timer interrupts and mtime/mcycle values
    - no functional warmup for advanced and virtual memory components (prefetcher, iTLB, dTLB, LLC)
    -->

    <!-- <ol>
      <li>Inaccurate at modeling asynchronous / timing-aware events (timer/external interrupts)</li>
      <li>Hardcoded for a single RTL design point</li>
      <li>Functional warmup models aren't validated against RTL</li>
      <li>Not warming up all necessary uarch state + resolving ambiguity in restoring arch state</li>
      <li>Interval embeddings are binary-aware (not portable) and not microarchitecture-aware (higher liklihood for errors)</li>
      <li>Modeling of I/O (off-chip communication, polling, interrupts) will be inaccurate due to uniform treatment of any memory access</li>
      <li>Interaction with core-coupled accelerators isn't properly embedded or checkpointable</li>
    </ol>-->
  </section>
</section>

<section>
  <section class="center">
    <h2>6.a: Validating Functional Warmup Models</h2>
  </section>

  <section>
    <h2>Validation Flow</h2>
    <p class="center fragment">Functional warmup models need to be validated against the behavior of their modeled RTL</p>

    <div class="center fragment">
      <img src="./figs/dynamic/tidalsim/validation_flow.svg" />
      <figcaption class="small">The flow for validating RTL against its functional warmup model (specifically an L1 cache) using SimCommand, parametric generators, and fuzzing.</figcaption>
    </div>
  </section>

  <section class="center">
    <div class="center">
      <img src="./figs/dynamic/tidalsim/validation_flow.svg" />
    </div>
  </section>

  <section>
    <h2>SimCommand: A Fast RTL Simulation API</h2>
    <ul>
      <li class="fragment">Testbench API embedded in Scala<sup>[1]</sup></li>
      <li class="fragment">Uses chiseltest as the simulator interface</li>
      <li class="fragment">Functional: testbench description and interpretation are split</li>
    </ul>

    <pre class="fragment"><code class="language-scala" data-trim data-noescape>
def enqueue(data: T): Command[Unit] = for {
    _ &lt;- poke(io.bits, data)
    _ &lt;- poke(io.valid, true.B)
    _ &lt;- waitUntil(io.ready, true.B)
    _ &lt;- step(1)
    _ &lt;- poke(io.valid, false.B)
} yield ()
    </pre></code>

    <ul class="smallish">
      <li class="fragment">20x faster than cocotb and chiseltest, parity with SystemVerilog + VCS</li>
      <li class="fragment">Enables writing performant testbenches with fork/join constructs in Scala</li>
    </ul>

    <div class="fragment">
    <hr>
    <div class="verysmall">
      <p class="footnote">
      [1]: Iyer, Vighnesh, et. al., SimCommand: A High Performance Multi-Threaded RTL Testbench API, OSCAR Workshop 2022
      </p>
    </div>
    </div>
  </section>

  <section class="center">
    <div class="center">
      <img src="./figs/dynamic/tidalsim/validation_flow.svg" />
    </div>
  </section>

  <section>
    <h2>Parametric Random Stimulus Generators</h2>

    <ul class="small">
      <li class="fragment">We designed a Scala eDSL for parametric random stimulus generation<sup>[1]</sup></li>
      <li class="fragment">Supports constrained and imperative randomization of Scala and Chisel datatypes</li>
    </ul>

    <pre class="fragment"><code class="language-scala" data-trim data-noescape>
val intGen: Gen[Int] = Gen[Int].range(0, 100)
</pre></code>

    <pre class="fragment"><code class="language-scala" data-trim data-noescape>
val seqGen: Gen[Seq[Int]] = for {
  lit &lt;- Gen.range(1, 100)
  tailGen &lt;- Gen.oneOf(Gen(Seq()) -&gt; 0.1, seqGen -&gt; 0.9),
  seqn &lt;- tailGen.map(t =&gt; lit +: t)
} yield seqn
</pre></code>

    <pre class="fragment"><code class="language-scala" data-trim data-noescape>
object MemOp extends ChiselEnum
case class MemTx extends Bundle {
  val addr = UInt(32.W)
  val data = UInt(64.W)
  val op = MemOp
}
val memTxGen: Gen[MemTx] = Gen[MemTx].uniform
</pre></code>

    <div class="fragment">
    <hr>
    <div class="verysmall">
      <p class="footnote">
      [1]: Iyer, Vighnesh, et. al., New Embedded DSLs for HW Design and Verification, PLARCH Workshop 2023
      </p>
    </div>
    </div>
  </section>

  <section class="center">
    <div class="center">
      <img src="./figs/dynamic/tidalsim/validation_flow.svg" />
    </div>
  </section>

  <section>
    <h2>RTL Coverage for Simulation Feedback</h2>

    <div class="container" style="grid-template-columns:1fr 1fr">
      <div>
        <img width="100%" src="./figs/sic-asplos23/1_coverage_figure_m_n.svg" />
      </div>
      <div>
        <ul class="smallish">
          <li class="fragment">Coverage implemented as a hardware IR compiler pass rather than baked into the RTL simulator</li>
          <li class="fragment">Easy to add new coverage metrics via static analysis of the RTL netlist</li>
          <li class="fragment">Leverage simulator independent coverage methodology for coverage instrumentation of long-lived uArch RTL</li>
        </ul>
      </div>
    </div>

    <div class="fragment">
    <hr>
    <div class="verysmall">
      <p class="footnote">
      [1]: Laeufer, Kevin; Iyer, Vighnesh, et. al., Simulator Independent Coverage for RTL Hardware Languages, ASPLOS 2023
      </p>
    </div>
    </div>
  </section>

  <section class="center">
    <div class="center">
      <img src="./figs/dynamic/tidalsim/validation_flow.svg" />
    </div>
  </section>

  <section>
    <h2>Parametric Fuzzing</h2>

    <ul class="smallish">
      <li class="fragment">Leverage fast RTL simulation APIs, parametric stimulus generators, and coverage instrumentation for <em>parametric fuzzing</em><sup>[1]</sup></li>
    </ul>

    <img class="fragment" src="./figs/fuzzing/parametric_fuzzing_loop.svg" />

    <ul class="smallish">
      <li class="fragment">Parametric fuzzing mutates the bytestream <em>going into</em> a parametric generator rather than the DUT directly<sup>[2]</sup></li>
      <li class="fragment">We augment typical parametric fuzzing with <em>mark-driven mutation</em></li>
    </ul>

    <div class="fragment">
    <hr>
    <div class="verysmall">
      <p class="footnote">
      [1]: Iyer, Vighnesh, et. al., New Embedded DSLs for HW Design and Verification, PLARCH Workshop 2023<br />
      [2]: Padhye, R., Lemieux, C., Sen, K., Papadakis, M. and Le Traon, Y., 2019. Semantic fuzzing with zest. ACM SIGSOFT.
      </p>
    </div>
    </div>
  </section>

  <section>
    <h2>Parametric Fuzzing - Demo Using Spike</h2>

    <div class="center">
      <img width="80%" class="fragment" src="./figs/fuzzing/spike_fuzzing.svg" />
    </div>

    <div class="container" style="grid-template-columns: 1.4fr 1fr;">
      <div>
        <ul class="smallish">
          <li class="fragment">Use spike's L1 dcache model's miss rate as feedback to produce RISC-V programs that maximize it</li>
          <li class="fragment">Using parametric fuzzing, we can automatically construct RISC-V programs to maximize any uArch metric given a small set of RISC-V sequence primitives</li>
        </ul>
      </div>
      <div>
        <img width="100%" class="fragment" src="./figs/fuzzing/spike_fuzzing_result.png" />
      </div>
    </div>
  </section>
</section>

<section>
  <section class="center">
    <h2>6.b: Putting the 'Tidal' in TidalSim</h2>
  </section>

  <section>
    <h2 style="font-size:1.9rem;">Issues with Time Modeling in Sampled Simulation</h2>

    <ul class="smallish">
      <li class="fragment">Prior work runs uArch simulators in "syscall emulation" mode when evaluating workloads (e.g. SPEC), not modeling any OS-application interactions</li>
      <li class="fragment">Real workloads contain many interactions between processes and the OS which are sensitive to the modeling of time</li>
    </ul>

    <div class="center fragment">
      <img width="60%" src="./figs/dynamic/tidalsim/timer_interrupts.svg" />
    </div>

    <p class="center fragment">Consider timer interrupts: naive functional simulators will just advance one timestep per commited instruction, not matching RTL!</p>
  </section>

  <section>
    <h2>TidalSim to Model Time Accurately</h2>

    <div class="center fragment">
      <img width="80%" src="./figs/dynamic/tidalsim/timer_interrupts.svg" />
    </div>

    <ul class="smallish">
      <li class="fragment">We propose bouncing between functional and RTL simulation, where performance metrics from RTL sim impacts time advancement in functional sim</p>
      <li class="fragment">To avoid simulating every interval in RTL sim, we leverage interval embeddings to estimate IPC on the fly</li>
    </ul>
    <!-- Insert image of bouncing between simulators and using interval embeddings to estimate actual time advancement-->
  </section>
</section>

<section>
  <section class="center">
    <h2>6.c: Sampled Simulation with Accelerators</h2>
  </section>

  <section>
    <h2>What Makes Accelerators Suitable for Sampled Simulation?</h2>

    <ul>
      <li class="fragment">Accelerator architectural state is large and explicit
        <ul>
          <li class="fragment">{{ rightarrow }} snapshotting is easy</li>
          <li class="fragment">{{ rightarrow }} functional warmup is unnecessary</li>
        </ul>
      </li>
      <li class="fragment">Accelerator usage is often repeated in workloads
        <ul>
          <li class="fragment">{{ rightarrow }} clustering accelerator usage embeddings is reasonable</li>
          <li class="fragment">{{ rightarrow }} potential for massive simulation throughput improvement</li>
        </ul>
      </li>
      <li class="fragment">Accelerator behavior is consistent
        <ul>
          <li class="fragment">{{ rightarrow }} accelerator performance is consistent from one dataset to another</li>
          <li class="fragment">{{ rightarrow }} embeddings don't need to be aware of the accelerator microarchitecture / latent state</li>
        </ul>
      </li>
    </ul>
    <!-- Talk about how accelerator arch state is explicit and accelerators often don't have long-lived uarch state (that requires functional warmup) -->
    <!-- Extend arch snapshotting to accelerator state too + add restoration capabilities for accelerator state -->
  </section>

  <section>
    <h2>Extending Interval Embeddings to Accelerators</h2>

    <div class="center">
      <img src="./figs/dynamic/tidalsim/accelerators.svg" />
    </div>

    <ul class="smallish">
      <li class="fragment">Incorporate accelerator state and the semantics of the accelerator ISA to the embedding</li>
      <li class="fragment">Can capture and embed accelerator interactions with system memory and with internal compute units</li>
      <li class="fragment">In the case of Gemmini, we must also consider instruction dependencies and out-of-order execution + memory contention from multiple accelerators</li>
    </ul>
    <!-- Need to incorporate accelerator state and the semantics of accelerator ISA instructions to the embedding.
    Consider case of Gemmini - intervals are similar if they execute similar gemmini instructions under same gemmini configuration. can use number of bytes mvin-ed / mvout-ed from sp/acc as a feature.
    Feature tuning needs to be precise here.-->
  </section>
</section>

<section>
  <section class="center">
    <h2>Backup: 6.d: Generalizing the Spectrum of Sampled Simulation</h2>
    <!-- generalization + streaming (no preprocessing step required)
      <li>Not general or streaming
        <ul>
          <li>Hardcoded Simpoint-style sampled simulation</li>
          <li>Requires multiple passes over the commit trace / multiple runs of spike</li>
        </ul>
      </li>
    -->
  </section>

    <!-- - We have implemented one specific simulator design point, but now we will generalize it
    - We will devise a parameterized simulator that can implement SMARTs, Simpoint, and hybrid-embedding/sampling approaches to simulation
    - Our formalization will
        - Produce output metrics such as cost, runtime, throughput, latency, time granularity, error bounds
        - In terms of variables such as number of dynamic instructions, number of cores, RTL sim throughput, and of course the simulation methodology
      -->

  <section>
    <h2>Sampled Simulation Techniques</h2>

    <div class="center fragment">
      <img width="70%" src="./figs/dynamic/tidalsim/simulation_techniques.svg" />
    </div>

    <p class="center fragment">Simulation techniques encompass SMARTS, SimPoint, hybrid variants, eager parallel RTL simulation, and many more</p>
  </section>

  <section>
    <h2>A Formalization and Simulation Model</h2>

    <div class="center fragment">
      <img width="40%" src="./figs/dynamic/tidalsim/simulation_techniques.svg" />
    </div>

    <ol class="small">
      <li class="fragment">Only considering techniques that can operate in a streaming fashion, develop a parameterized version of TidalSim
        <ul>
          <li>Streaming necessitates new incremental unsupervised learning algorithms</li>
        </ul>
      </li>
      <li class="fragment">Formalize the interfaces between arch sim, uArch models, and RTL sim</li>
      <li class="fragment">Formalize and parameterize simulation methodology to encompass all prior techniques
        <ul>
          <li>Consider <strong>input parameters</strong> such as interval length ($N$), number of host cores ($n_{cores}$), RTL simulation throughput ($T_{rtl}$), sampling technique ($i \rightarrow \{0, 1\}$)</li>
          <li>Produce estimated <strong>output metrics</strong> such as cost, runtime, aggregate throughput, latency, time-granularity of output, error bounds</li>
        </ul>
      </li>
    </ol>
  </section>

  <section>
    <h2>PC/Binary-Agnostic Embeddings</h2>
    <!-- <li>{{ rightarrow }} generalizing representative sampling for PC/binary-agnostic interval embeddings to enable running multi-process workloads in an OS</li>-->

    <ul>
      <li class="fragment">Basic block embedding assumes
        <ul>
          <li>There is a static PC {{ rightarrow }} basic block mapping</li>
          <li>Intervals with similar basic block traversals have similar uArch behavior</li>
        </ul>
      </li>
      <li class="fragment">Our embeddings should be PC/binary-agnostic to support portability and multi-process workloads in an OS
        <ul>
          <li>Most prior work only runs single-process workloads using syscall proxies</li>
          <li>Real workloads are heavily affected by interactions between the OS and userspace processes</li>
        </ul>
      </li>
      <li class="fragment">We will explore embeddings with features such as
        <ul>
          <li>Instruction mix, function call frequency, instruction dependencies</li>
          <li>Microarchitectural behaviors: I/D cache misses, BP model mispredicts, TLB behavior</li>
        </ul>
      </li>
    </ul>
  </section>
</section>


<!-- <section>
  <h2>2. Modeling Timing-Aware Events (Dynamic Simulation)</h2>
  going from one-direction simulation to dynamically changing simulators up and down the stack during execution
</section>

<section>
  <h2>3. Leveraging Chisel for State Injection</h2>
</section>

<section>
  <h2>4. Validating Functional Warmup Models</h2>
</section>

<section>
  <h2>5. Long-Lived uArch State Identification</h2>
</section>

<section>
  <h2>5. Resolving Ambiguity in Forcing Arch State</h2>
</section>

<section>
  <h2>6. Better Interval Embeddings</h2>
</section>

<section>
  <h2>7. Modeling I/O</h2>
</section>

<section>
  <h2>8. Sampled Simulation with Accelerators</h2>
</section>
-->
