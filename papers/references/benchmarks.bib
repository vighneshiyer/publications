% Benchmark suites

@inproceedings{embench,
  author = {Almeida, Mario and Laskaridis, Stefanos and Leontiadis, Ilias and Venieris, Stylianos I. and Lane, Nicholas D.},
  title = {EmBench: Quantifying Performance Variations of Deep Neural Networks across Modern Commodity Devices},
  year = {2019},
  isbn = {9781450367714},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3325413.3329793},
  doi = {10.1145/3325413.3329793},
  abstract = {In recent years, advances in deep learning have resulted in unprecedented leaps in diverse tasks spanning from speech and object recognition to context awareness and health monitoring. As a result, an increasing number of AI-enabled applications are being developed targeting ubiquitous and mobile devices. While deep neural networks (DNNs) are getting bigger and more complex, they also impose a heavy computational and energy burden on the host devices, which has led to the integration of various specialized processors in commodity devices. Given the broad range of competing DNN architectures and the heterogeneity of the target hardware, there is an emerging need to understand the compatibility between DNN-platform pairs and the expected performance benefits on each platform. This work attempts to demystify this landscape by systematically evaluating a collection of state-of-the-art DNNs on a wide variety of commodity devices. In this respect, we identify potential bottlenecks in each architecture and provide important guidelines that can assist the community in the co-design of more efficient DNNs and accelerators.},
  booktitle = {The 3rd International Workshop on Deep Learning for Mobile Systems and Applications},
  pages = {1â€“6},
  numpages = {6},
  keywords = {on-device inference, deep neural networks, mobile devices},
  location = {Seoul, Republic of Korea},
  series = {EMDL '19}
}
